{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c09ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import concurrent.futures\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e94469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to loads through all CSV files\n",
    "def read_all_datasets(data_folder):\n",
    "    \n",
    "    datasets = {}\n",
    "\n",
    "    csv_files = [\n",
    "        'vitals_hourly.csv', 'admissions.csv', 'antibiotics.csv', 'bloodculture.csv',\n",
    "        'gcs_hourly.csv', 'icd9_diag.csv', 'icustays.csv', 'labs_hourly.csv',\n",
    "        'output_hourly.csv', 'patients.csv', 'pt_icu_outcome.csv', 'pt_stay_hr.csv',\n",
    "        'pt_weight.csv', 'pv_mechvent.csv', 'transfers.csv', 'vasopressors.csv'\n",
    "    ]\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            datasets[file.replace('.csv', '')] = pd.read_csv(file_path)\n",
    "        else:\n",
    "            print(f\"File not found: {file}\")\n",
    "\n",
    "    return datasets\n",
    "\n",
    "data_folder = '/Users\\lukac\\OneDrive\\Desktop\\HDAT-9910-Capstone/mimic_data/'\n",
    "all_datasets = read_all_datasets(data_folder)\n",
    "\n",
    "# Assign all files to a dataframe for exploration\n",
    "admissions_df = all_datasets['admissions']\n",
    "vitals_hourly_df = all_datasets['vitals_hourly']\n",
    "antibiotics_df = all_datasets['antibiotics']\n",
    "bloodculture_df = all_datasets['bloodculture']\n",
    "gcs_hourly_df = all_datasets['gcs_hourly']\n",
    "icd9_diag_df = all_datasets['icd9_diag']\n",
    "icustays_df = all_datasets['icustays']\n",
    "labs_hourly_df = all_datasets['labs_hourly']\n",
    "pt_stay_hr_df = all_datasets['pt_stay_hr']\n",
    "pt_icu_outcome_df = all_datasets['pt_icu_outcome']\n",
    "patients_df = all_datasets['patients']\n",
    "output_hourly_df = all_datasets['output_hourly']\n",
    "pt_weight_df = all_datasets['pt_weight']\n",
    "pv_mechvent_df = all_datasets['pv_mechvent']\n",
    "transfers_df = all_datasets['transfers']\n",
    "vasopressors_df = all_datasets['vasopressors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "edd05fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in patients_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    patients_df[col].fillna(patients_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in patients_df.select_dtypes(include=['object']).columns:\n",
    "    patients_df[col].fillna(patients_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "patients_df.drop_duplicates(inplace=True)\n",
    "patients_df = patients_df.drop(columns =['dod_ssn', 'dob','dod_hosp', 'row_id', 'dod'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d30a47f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in vitals_hourly_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    vitals_hourly_df[col].fillna(vitals_hourly_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in vitals_hourly_df.select_dtypes(include=['object']).columns:\n",
    "    vitals_hourly_df[col].fillna(vitals_hourly_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "vitals_hourly_df.drop_duplicates(inplace=True)\n",
    "vitals_hourly_df = vitals_hourly_df.drop(columns =['fio2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6196a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in gcs_hourly_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    gcs_hourly_df[col].fillna(gcs_hourly_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in gcs_hourly_df.select_dtypes(include=['object']).columns:\n",
    "    gcs_hourly_df[col].fillna(gcs_hourly_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "gcs_hourly_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a5216c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in labs_hourly_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    labs_hourly_df[col].fillna(labs_hourly_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in labs_hourly_df.select_dtypes(include=['object']).columns:\n",
    "    labs_hourly_df[col].fillna(labs_hourly_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "labs_hourly_df.drop_duplicates(inplace=True)\n",
    "labs_hourly_df = labs_hourly_df.drop(columns =['alaninetransaminase', 'aspartatetransaminase', 'albumin', 'bilirubin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2588c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in pt_icu_outcome_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    pt_icu_outcome_df[col].fillna(pt_icu_outcome_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in pt_icu_outcome_df.select_dtypes(include=['object']).columns:\n",
    "    pt_icu_outcome_df[col].fillna(pt_icu_outcome_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "pt_icu_outcome_df.drop_duplicates(inplace=True)\n",
    "pt_icu_outcome_df = pt_icu_outcome_df.drop(columns =['hadm_id', 'icu_expire_flag', 'row_id','dob', 'admittime', 'dischtime','ttd_days','dod','hospital_expire_flag', 'intime', 'los','hosp_deathtime','outtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "78156eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the median\n",
    "for col in icustays_df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    icustays_df[col].fillna(icustays_df[col].median(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill missing values with the mode\n",
    "for col in icustays_df.select_dtypes(include=['object']).columns:\n",
    "    icustays_df[col].fillna(icustays_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "icustays_df.drop_duplicates(inplace=True)\n",
    "icustays_df = icustays_df.drop(columns =['row_id', 'dbsource', 'hadm_id','first_careunit', 'last_careunit', 'first_wardid','last_wardid','intime','outtime', 'intime', 'los'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4fb207af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records within the first 24 hours\n",
    "vitals_first_24h = vitals_hourly_df[vitals_hourly_df['hr'] <= 24]\n",
    "vitals_first_24h = vitals_first_24h[vitals_hourly_df['hr'] >=0]\n",
    "# Aggregate the data (mean, min, max)\n",
    "vitals_agg = vitals_first_24h.groupby('icustay_id').agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "# Adjust the column names in the aggregated DataFrame\n",
    "vitals_agg.columns = ['_'.join(col).rstrip('_') if col[0] != 'icustay_id' else col[0] for col in vitals_agg.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f51a6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records within the first 24 hours\n",
    "labs_first_24h = labs_hourly_df[labs_hourly_df['hr'] <= 24]\n",
    "labs_first_24h = labs_first_24h[labs_first_24h['hr'] >=0]\n",
    "# Aggregate the data (mean, min, max)\n",
    "labs_agg = labs_first_24h.groupby('icustay_id').agg(['mean', 'min', 'max']).reset_index()\n",
    "\n",
    "# Adjust the column names in the aggregated DataFrame\n",
    "labs_agg.columns = ['_'.join(col).rstrip('_') if col[0] != 'icustay_id' else col[0] for col in labs_agg.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e24540f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records within the first 24 hours\n",
    "gcs_first_24h = gcs_hourly_df[gcs_hourly_df['hr'] <= 24]\n",
    "gcs_first_24h = gcs_first_24h[gcs_first_24h['hr'] >= 0]\n",
    "\n",
    "# Aggregate the data (mean, min, max)\n",
    "gcs_agg = gcs_first_24h.groupby('icustay_id').agg(['mean', 'min','max']).reset_index()\n",
    "\n",
    "# Adjust the column names in the aggregated DataFrame\n",
    "gcs_agg.columns = ['_'.join(col).rstrip('_') if col[0] != 'icustay_id' else col[0] for col in gcs_agg.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1faf5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge patients and ICU stays\n",
    "merged_df = pd.merge(patients_df, icustays_df, on='subject_id', how='left')\n",
    "merged_df['icustay_id'] = merged_df['icustay_id'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5851ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in aggregated vitals, labs, and GCS data\n",
    "merged_df = pd.merge(merged_df, vitals_agg, on='icustay_id', how='left')\n",
    "merged_df = pd.merge(merged_df, labs_agg, on='icustay_id', how='left')  \n",
    "merged_df = pd.merge(merged_df, gcs_agg, on='icustay_id', how='left')  \n",
    "# Merge in ICU outcomes\n",
    "merged_df = pd.merge(merged_df, pt_icu_outcome_df, on='icustay_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b5f68870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not of importance\n",
    "merged_df = merged_df.drop(columns =['subject_id_x', 'hr_mean_x', 'hr_min_x','hr_max_x', 'hr_mean_y', 'hr_min_y','hr_max_y','subject_id_y','expire_flag_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dc00cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'gender' to bindary, 1 for 'M' and 0 for 'F'\n",
    "merged_df['gender'] = merged_df['gender'].map({'M': 1, 'F': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07d474e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for easy interpretation\n",
    "merged_df.rename(columns={'expire_flag': 'mortality', 'age_years'  : 'age'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f5baadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe so we can load it into our other scripts\n",
    "output_csv_path = '/Users\\lukac\\OneDrive\\Desktop\\HDAT-9910-Capstone/df_24Hrs.csv'\n",
    "merged_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1655b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57222247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9843328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
